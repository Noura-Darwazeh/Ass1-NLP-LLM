# -*- coding: utf-8 -*-
"""Assignment1.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1s1SB5pwg0PHa6taX1FFvB-zfdLUvkW-8
"""

import pandas as pd
import string
import nltk
from nltk.corpus import stopwords
from nltk.stem import PorterStemmer
import matplotlib.pyplot as plt

nltk.download('stopwords')

from google.colab import files

uploaded = files.upload()

df = pd.read_csv("Fake.csv")

df.head()

stop_words = set(stopwords.words('english'))
stemmer = PorterStemmer()

def clean_text(text):
    text = text.lower()

    text = text.translate(str.maketrans('', '', string.punctuation))

    words = text.split()

    words = [word for word in words if word not in stop_words]

    words = [stemmer.stem(word) for word in words]

    return " ".join(words)

df['clean_text'] = df['text'].astype(str).apply(clean_text)

df[['text', 'clean_text']].head()

def tokenize(text):
    return text.split()

df['tokens'] = df['clean_text'].apply(tokenize)

df['word_count'] = df['tokens'].apply(len)

average_words = df['word_count'].mean()
print(f"The average number of words per document: {average_words:.2f}")

plt.figure(figsize=(10, 5))
plt.hist(df['word_count'], bins=50, color='skyblue', edgecolor='black')
plt.title("Distribution of Word Count per Document")
plt.xlabel("Number of Words")
plt.ylabel("Number of Documents")
plt.grid(True)
plt.show()

df.to_csv("cleaned_news.csv", index=False)

files.download("cleaned_news.csv")